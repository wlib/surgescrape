#!/usr/bin/env ruby
# SurgeScrape - Scrape your surge.sh website's files
# Daniel Ethridge

require "surgescrape"
include SurgeScrape

usage = "Usage : `sscrape website.surge.sh`"
version = "SurgeScrape version : 0.1.1" #{SurgeScrape::VERSION}"

help = "\n#{usage}

#{version}

A simple utility, just specify a domain
and watch all the files download. Run each time
you need to update your directory, the tool won't 
download untouched files.

--------------------------------------------------

If you find a bug, want extra features, or have a suggestion,
make a branch on github : https://github.com/wlib/surgescrape\n\n"

# If there are no arguments, print usage
if ARGV.length == 0
  puts usage
  exit
end

# Argument "parser", though only takes one argument...
arg = ARGV[0].downcase
case (arg)
  when "help", "--help", "h", "-h", "?"
    puts help
    exit
  when "version", "--version", "v", "-v"
    puts version
    exit
  else
    if arg.match( /^https:\/\/.+/i )
      scrape(arg)
      exit
    elsif arg.match( /^http:\/\/.+/i )
      puts "https:// only"
      exit
    else
      scrape("https://#{arg}")
      exit
    end
    exit
end